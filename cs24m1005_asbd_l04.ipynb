{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9374317,
          "sourceType": "datasetVersion",
          "datasetId": 5685965
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:22.644445Z",
          "iopub.execute_input": "2024-09-19T06:58:22.644966Z",
          "iopub.status.idle": "2024-09-19T06:58:22.659733Z",
          "shell.execute_reply.started": "2024-09-19T06:58:22.644919Z",
          "shell.execute_reply": "2024-09-19T06:58:22.658195Z"
        },
        "trusted": true,
        "id": "ozWmR1kUdaIB",
        "outputId": "e26a1292-24eb-4790-be7e-410d57cfaa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/avacado-dataset/Avocado Dataset.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # COM 526 P ANALYTICS & SYSTEMS OF BIG DATA PRACTICE â€“ PROBLEM SET IV"
      ],
      "metadata": {
        "id": "ZcHR13CydaIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Name: Sindhiya\n",
        "> Roll No: CS24M1005"
      ],
      "metadata": {
        "id": "MwH3Td3fdaIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "T3e6xfXWdaIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Suppose that the data for analysis includes the attribute age. The age values for the\n",
        "> data tuples are (in increasing order) 13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25, 25, 25, 25,30, 33, 33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70.\n",
        ">> (a) Use min-max normalization to transform the values of age to the range[0:1].\n",
        ">>>(b) Use z-score normalization to transform the values of age.\n",
        ">>>>(c) Use normalization by decimal scaling to transform the values of age such that the transformed value is less than 1."
      ],
      "metadata": {
        "id": "hBNqHrFSdaIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) min-max normalization\n",
        "\n",
        "![image.png](attachment:906f6a26-91c8-447a-8062-30df0e918444.png)"
      ],
      "metadata": {
        "id": "YhoitBDWdaId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Age values\n",
        "ages = np.array([13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25, 25, 25, 25,\n",
        "                 30, 33, 33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70])\n",
        "\n",
        "# Min-max normalization\n",
        "min_age = np.min(ages)\n",
        "max_age = np.max(ages)\n",
        "min_max_normalized = (ages - min_age) / (max_age - min_age)\n",
        "print(\"Min-Max Normalized Ages:\", min_max_normalized)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:59:05.200405Z",
          "iopub.execute_input": "2024-09-19T06:59:05.200874Z",
          "iopub.status.idle": "2024-09-19T06:59:05.210841Z",
          "shell.execute_reply.started": "2024-09-19T06:59:05.200834Z",
          "shell.execute_reply": "2024-09-19T06:59:05.209648Z"
        },
        "trusted": true,
        "id": "hL9MGJgDdaIf",
        "outputId": "a7ffb401-c661-4b5a-d1f0-03c0591fdb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Min-Max Normalized Ages: [0.         0.03508772 0.05263158 0.05263158 0.10526316 0.12280702\n 0.12280702 0.14035088 0.15789474 0.15789474 0.21052632 0.21052632\n 0.21052632 0.21052632 0.29824561 0.35087719 0.35087719 0.38596491\n 0.38596491 0.38596491 0.38596491 0.40350877 0.47368421 0.56140351\n 0.57894737 0.68421053 1.        ]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Z-Score Normalization:\n",
        "\n",
        "![image.png](attachment:2e6afa6a-71da-4741-9bb3-7940e27732ce.png)"
      ],
      "metadata": {
        "id": "6MqysD88daIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Z-score normalization\n",
        "mean_age = np.mean(ages)\n",
        "std_age = np.std(ages)\n",
        "z_score_normalized = (ages - mean_age) / std_age\n",
        "print(\"Z-Score Normalized Ages:\", z_score_normalized)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:22.676180Z",
          "iopub.execute_input": "2024-09-19T06:58:22.676740Z",
          "iopub.status.idle": "2024-09-19T06:58:22.691787Z",
          "shell.execute_reply.started": "2024-09-19T06:58:22.676678Z",
          "shell.execute_reply": "2024-09-19T06:58:22.689979Z"
        },
        "trusted": true,
        "id": "fHOFMn9edaIk",
        "outputId": "f97bd2ca-a503-4865-c3c9-89af56faecb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Z-Score Normalized Ages: [-1.33564599e+00 -1.17816807e+00 -1.09942912e+00 -1.09942912e+00\n -8.63212252e-01 -7.84473297e-01 -7.84473297e-01 -7.05734341e-01\n -6.26995386e-01 -6.26995386e-01 -3.90778520e-01 -3.90778520e-01\n -3.90778520e-01 -3.90778520e-01  2.91625761e-03  2.39133124e-01\n  2.39133124e-01  3.96611035e-01  3.96611035e-01  3.96611035e-01\n  3.96611035e-01  4.75349990e-01  7.90305812e-01  1.18400059e+00\n  1.26273954e+00  1.73517328e+00  3.15247448e+00]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Decimal Scaling Normalization:\n",
        "\n",
        "![image.png](attachment:8c4b4394-6ca3-49b0-8ef6-6e43a700d117.png)"
      ],
      "metadata": {
        "id": "zxn6YNAsdaIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decimal scaling normalization\n",
        "max_abs_age = np.max(np.abs(ages))\n",
        "j = np.ceil(np.log10(max_abs_age))\n",
        "decimal_scaling_normalized = ages / (10**j)\n",
        "print(\"Decimal Scaling Normalized Ages:\", decimal_scaling_normalized)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:22.694911Z",
          "iopub.execute_input": "2024-09-19T06:58:22.695706Z",
          "iopub.status.idle": "2024-09-19T06:58:22.707121Z",
          "shell.execute_reply.started": "2024-09-19T06:58:22.695536Z",
          "shell.execute_reply": "2024-09-19T06:58:22.705626Z"
        },
        "trusted": true,
        "id": "i0JA_IRidaIp",
        "outputId": "d51ad873-9efe-4cab-ad55-281267943845"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Decimal Scaling Normalized Ages: [0.13 0.15 0.16 0.16 0.19 0.2  0.2  0.21 0.22 0.22 0.25 0.25 0.25 0.25\n 0.3  0.33 0.33 0.35 0.35 0.35 0.35 0.36 0.4  0.45 0.46 0.52 0.7 ]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "VFdya-skdaIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Operations on the Avocado Dataset\n",
        "\n",
        "(a) Sorting and Smoothing Total Volume\n",
        "We need to sort the \"Total Volume\" attribute and apply binning techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "BlqXIrhgdaIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/kaggle/input/avacado-dataset/Avocado Dataset.csv')\n",
        "\n",
        "# Sort by 'Total Volume'\n",
        "df_sorted = df.sort_values(by='Total Volume')\n",
        "\n",
        "# Number of bins\n",
        "bins = 250\n",
        "df_sorted['Total Volume Binned'] = pd.qcut(df_sorted['Total Volume'], bins, duplicates='drop')\n",
        "\n",
        "# Bin Smoothing: Bin Means (explicitly set observed=False)\n",
        "bin_means = df_sorted.groupby('Total Volume Binned', observed=False)['Total Volume'].mean()\n",
        "df_sorted['Total Volume Bin Means'] = df_sorted['Total Volume Binned'].apply(lambda x: bin_means[x])\n",
        "\n",
        "# Bin Smoothing: Bin Medians (explicitly set observed=False)\n",
        "bin_medians = df_sorted.groupby('Total Volume Binned', observed=False)['Total Volume'].median()\n",
        "df_sorted['Total Volume Bin Medians'] = df_sorted['Total Volume Binned'].apply(lambda x: bin_medians[x])\n",
        "\n",
        "# Bin Smoothing: Bin Boundaries\n",
        "def bin_boundaries(x, bin_labels):\n",
        "    left, right = bin_labels.left, bin_labels.right\n",
        "    return left if x - left < right - x else right\n",
        "\n",
        "df_sorted['Total Volume Bin Boundaries'] = df_sorted.apply(\n",
        "    lambda row: bin_boundaries(row['Total Volume'], row['Total Volume Binned']), axis=1)\n",
        "\n",
        "# Display relevant columns\n",
        "df_sorted[['Total Volume', 'Total Volume Bin Means', 'Total Volume Bin Medians', 'Total Volume Bin Boundaries']]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:22.709037Z",
          "iopub.execute_input": "2024-09-19T06:58:22.709492Z",
          "iopub.status.idle": "2024-09-19T06:58:23.238422Z",
          "shell.execute_reply.started": "2024-09-19T06:58:22.709442Z",
          "shell.execute_reply": "2024-09-19T06:58:23.236964Z"
        },
        "trusted": true,
        "id": "xX3KJR3bdaIt",
        "outputId": "2aa241b8-8859-466d-ca1e-3e951a8eebbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Total Volume Total Volume Bin Means Total Volume Bin Medians  \\\n10381         84.56           7.357130e+02                   774.20   \n9437         379.82           7.357130e+02                   774.20   \n13189        385.55           7.357130e+02                   774.20   \n11698        419.98           7.357130e+02                   774.20   \n13193        472.82           7.357130e+02                   774.20   \n...             ...                    ...                      ...   \n5493    46324529.70           3.897352e+07              37352360.59   \n8353    47293921.60           3.897352e+07              37352360.59   \n5506    52288697.89           3.897352e+07              37352360.59   \n8366    61034457.10           3.897352e+07              37352360.59   \n9097    62505646.52           3.897352e+07              37352360.59   \n\n       Total Volume Bin Boundaries  \n10381                 8.455900e+01  \n9437                  8.455900e+01  \n13189                 8.455900e+01  \n11698                 8.455900e+01  \n13193                 8.455900e+01  \n...                            ...  \n5493                  3.399446e+07  \n8353                  3.399446e+07  \n5506                  6.250565e+07  \n8366                  6.250565e+07  \n9097                  6.250565e+07  \n\n[18250 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total Volume</th>\n      <th>Total Volume Bin Means</th>\n      <th>Total Volume Bin Medians</th>\n      <th>Total Volume Bin Boundaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10381</th>\n      <td>84.56</td>\n      <td>7.357130e+02</td>\n      <td>774.20</td>\n      <td>8.455900e+01</td>\n    </tr>\n    <tr>\n      <th>9437</th>\n      <td>379.82</td>\n      <td>7.357130e+02</td>\n      <td>774.20</td>\n      <td>8.455900e+01</td>\n    </tr>\n    <tr>\n      <th>13189</th>\n      <td>385.55</td>\n      <td>7.357130e+02</td>\n      <td>774.20</td>\n      <td>8.455900e+01</td>\n    </tr>\n    <tr>\n      <th>11698</th>\n      <td>419.98</td>\n      <td>7.357130e+02</td>\n      <td>774.20</td>\n      <td>8.455900e+01</td>\n    </tr>\n    <tr>\n      <th>13193</th>\n      <td>472.82</td>\n      <td>7.357130e+02</td>\n      <td>774.20</td>\n      <td>8.455900e+01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5493</th>\n      <td>46324529.70</td>\n      <td>3.897352e+07</td>\n      <td>37352360.59</td>\n      <td>3.399446e+07</td>\n    </tr>\n    <tr>\n      <th>8353</th>\n      <td>47293921.60</td>\n      <td>3.897352e+07</td>\n      <td>37352360.59</td>\n      <td>3.399446e+07</td>\n    </tr>\n    <tr>\n      <th>5506</th>\n      <td>52288697.89</td>\n      <td>3.897352e+07</td>\n      <td>37352360.59</td>\n      <td>6.250565e+07</td>\n    </tr>\n    <tr>\n      <th>8366</th>\n      <td>61034457.10</td>\n      <td>3.897352e+07</td>\n      <td>37352360.59</td>\n      <td>6.250565e+07</td>\n    </tr>\n    <tr>\n      <th>9097</th>\n      <td>62505646.52</td>\n      <td>3.897352e+07</td>\n      <td>37352360.59</td>\n      <td>6.250565e+07</td>\n    </tr>\n  </tbody>\n</table>\n<p>18250 rows Ã— 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Monthly and Annual Sales\n",
        "We need to group the data by month and year."
      ],
      "metadata": {
        "id": "W2SKoqiSdaIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' to datetime with dayfirst=True\n",
        "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
        "\n",
        "# Group by month\n",
        "df['Month'] = df['Date'].dt.to_period('M')\n",
        "monthly_sales = df.groupby('Month').agg({'Total Volume': 'sum'}).reset_index()\n",
        "\n",
        "# Group by year\n",
        "df['Year'] = df['Date'].dt.year\n",
        "annual_sales = df.groupby('Year').agg({'Total Volume': 'sum'}).reset_index()\n",
        "\n",
        "# Output monthly and annual sales\n",
        "monthly_sales, annual_sales\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T07:00:51.858103Z",
          "iopub.execute_input": "2024-09-19T07:00:51.858703Z",
          "iopub.status.idle": "2024-09-19T07:00:51.919540Z",
          "shell.execute_reply.started": "2024-09-19T07:00:51.858653Z",
          "shell.execute_reply": "2024-09-19T07:00:51.916572Z"
        },
        "trusted": true,
        "id": "ChY7kcgpdaIv",
        "outputId": "c72c339a-1d40-4a98-9baa-877d614d9467"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(      Month  Total Volume\n 0   2015-01  3.180852e+08\n 1   2015-02  3.626376e+08\n 2   2015-03  4.185831e+08\n 3   2015-04  3.441444e+08\n 4   2015-05  4.837840e+08\n 5   2015-06  3.818267e+08\n 6   2015-07  3.567019e+08\n 7   2015-08  4.192448e+08\n 8   2015-09  3.292188e+08\n 9   2015-10  3.057761e+08\n 10  2015-11  3.694400e+08\n 11  2015-12  2.960259e+08\n 12  2016-01  4.754058e+08\n 13  2016-02  4.286458e+08\n 14  2016-03  3.912124e+08\n 15  2016-04  4.018328e+08\n 16  2016-05  5.612305e+08\n 17  2016-06  4.103282e+08\n 18  2016-07  4.672753e+08\n 19  2016-08  3.707970e+08\n 20  2016-09  3.623033e+08\n 21  2016-10  3.602018e+08\n 22  2016-11  2.602093e+08\n 23  2016-12  3.314478e+08\n 24  2017-01  5.333330e+08\n 25  2017-02  4.714672e+08\n 26  2017-03  3.589034e+08\n 27  2017-04  4.898145e+08\n 28  2017-05  4.257305e+08\n 29  2017-06  4.104107e+08\n 30  2017-07  4.749037e+08\n 31  2017-08  3.383330e+08\n 32  2017-09  2.847795e+08\n 33  2017-10  3.627780e+08\n 34  2017-11  3.245193e+08\n 35  2017-12  4.593329e+08\n 36  2018-01  4.297071e+08\n 37  2018-02  4.977782e+08\n 38  2018-03  4.552690e+08,\n    Year  Total Volume\n 0  2015  4.385469e+09\n 1  2016  4.820890e+09\n 2  2017  4.934306e+09\n 3  2018  1.382754e+09)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Summarize Missing Values"
      ],
      "metadata": {
        "id": "GtvMlOFedaIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing Values Per Attribute:\", missing_values)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:23.287729Z",
          "iopub.execute_input": "2024-09-19T06:58:23.288117Z",
          "iopub.status.idle": "2024-09-19T06:58:23.305866Z",
          "shell.execute_reply.started": "2024-09-19T06:58:23.288078Z",
          "shell.execute_reply": "2024-09-19T06:58:23.304156Z"
        },
        "trusted": true,
        "id": "-Qmhjt-1daIx",
        "outputId": "c1a33c61-5c2f-48c5-b78f-bc81f4e2973c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Missing Values Per Attribute: Date             0\nAveragePrice    28\nTotal Volume     0\n4046             0\n4225             0\n4770             0\nTotal Bags       0\nSmall Bags       0\nLarge Bags       0\nXLarge Bags      0\ntype             0\nyear             0\nregion           0\nMonth            0\nYear             0\ndtype: int64\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Populate Missing Values for 'Average Price' by 'Region'\n"
      ],
      "metadata": {
        "id": "vLLXFmBqdaIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print column names to check for correct names\n",
        "print(df.columns)\n",
        "\n",
        "# Convert 'AveragePrice' to numeric to handle non-numeric data\n",
        "df['AveragePrice'] = pd.to_numeric(df['AveragePrice'], errors='coerce')\n",
        "\n",
        "# Ensure 'region' is spelled correctly by checking it in df.columns\n",
        "if 'region' in df.columns:\n",
        "    # Fill missing values in 'AveragePrice' based on 'region'\n",
        "    df['AveragePrice'] = df.groupby('region')['AveragePrice'].transform(\n",
        "        lambda grp: grp.fillna(grp.mean()))\n",
        "else:\n",
        "    print(\"'region' column not found. Check for any naming differences.\")\n",
        "\n",
        "    df['AveragePrice'] = df.groupby('Region')['AveragePrice'].transform(\n",
        "    lambda grp: grp.fillna(grp.mean()))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:23.307965Z",
          "iopub.execute_input": "2024-09-19T06:58:23.309672Z",
          "iopub.status.idle": "2024-09-19T06:58:23.356471Z",
          "shell.execute_reply.started": "2024-09-19T06:58:23.309621Z",
          "shell.execute_reply": "2024-09-19T06:58:23.354326Z"
        },
        "trusted": true,
        "id": "98BbuI_kdaI0",
        "outputId": "9a2de22b-dc17-4130-f645-2f163e24f48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Index(['Date', 'AveragePrice', 'Total Volume', '4046', '4225', '4770',\n       'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year',\n       'region', 'Month', 'Year'],\n      dtype='object')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Discretize 'Date' into {Old, New, Recent}\n",
        "We will categorize the years 2015, 2016 as \"Old,\" 2017 as \"New,\" and 2018 as \"Recent.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "SrVWdLoldaI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'Date' is in datetime format, specifying day comes first\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)\n",
        "\n",
        "# Extract the year from the 'Date' column\n",
        "df['Year'] = df['Date'].dt.year\n",
        "\n",
        "# Define the function to discretize the year\n",
        "def discretize_date(year):\n",
        "    if year in [2015, 2016]:\n",
        "        return 'Old'\n",
        "    elif year == 2017:\n",
        "        return 'New'\n",
        "    else:\n",
        "        return 'Recent'\n",
        "\n",
        "# Apply the function to create 'Date Category'\n",
        "df['Date Category'] = df['Year'].apply(discretize_date)\n",
        "\n",
        "# Display the 'Date' and 'Date Category' columns\n",
        "df[['Date', 'Date Category']]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-19T06:58:23.359504Z",
          "iopub.execute_input": "2024-09-19T06:58:23.359942Z",
          "iopub.status.idle": "2024-09-19T06:58:23.407847Z",
          "shell.execute_reply.started": "2024-09-19T06:58:23.359899Z",
          "shell.execute_reply": "2024-09-19T06:58:23.406313Z"
        },
        "trusted": true,
        "id": "hiXTEcFqdaI2",
        "outputId": "dbac0bdf-278e-4702-bcaa-9365dd9ef573"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date Date Category\n0     2015-12-27           Old\n1     2015-12-20           Old\n2     2015-12-13           Old\n3     2015-12-06           Old\n4     2015-11-29           Old\n...          ...           ...\n18245 2018-01-28        Recent\n18246 2018-01-21        Recent\n18247 2018-01-14        Recent\n18248 2018-01-07        Recent\n18249 2018-03-18        Recent\n\n[18250 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Date Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-12-27</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-12-20</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-12-13</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-12-06</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-11-29</td>\n      <td>Old</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18245</th>\n      <td>2018-01-28</td>\n      <td>Recent</td>\n    </tr>\n    <tr>\n      <th>18246</th>\n      <td>2018-01-21</td>\n      <td>Recent</td>\n    </tr>\n    <tr>\n      <th>18247</th>\n      <td>2018-01-14</td>\n      <td>Recent</td>\n    </tr>\n    <tr>\n      <th>18248</th>\n      <td>2018-01-07</td>\n      <td>Recent</td>\n    </tr>\n    <tr>\n      <th>18249</th>\n      <td>2018-03-18</td>\n      <td>Recent</td>\n    </tr>\n  </tbody>\n</table>\n<p>18250 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}